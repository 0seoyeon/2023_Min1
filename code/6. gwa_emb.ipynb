{"cells":[{"cell_type":"markdown","metadata":{"id":"aQYeFLqrU4fP"},"source":["# import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyaAMPVIU4fR"},"outputs":[],"source":["from minone import CD, model, trainer, tokenization\n","\n","from tqdm import tqdm\n","from ast import literal_eval\n","\n","\n","import torch\n","from torch.utils.data import Dataset\n","import pandas as pd\n","import re\n","from transformers import BertModel, BertTokenizer, DistilBertModel\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VFZWvCZeU4fS"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eltq16f9U4fS"},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vhPQACCLU4fS","outputId":"0304058e-53e5-42d9-f5f4-af667bc58df4"},"outputs":[{"data":{"text/plain":["device(type='mps')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# GPU 사용 가능 여부 확인\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","elif torch.backends.mps.is_available():\n","    device = torch.device(\"mps\")\n","else:\n","    device = torch.device(\"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{"id":"-jsEyMLuU4fT"},"source":["# 데이터 및 모델 로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1KwHjjF2U4fT"},"outputs":[],"source":["gwa_df = pd.read_csv('../data//0. 구_과_하는일_통합.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFos1gk1U4fT","outputId":"8521aebf-46c8-4f51-b7aa-e1e2a8f32e3d"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n","The class this function is called from is 'KoBertTokenizer'.\n"]}],"source":["def extract_korean_text(text):\n","    if isinstance(text, str):\n","        korean_pattern = re.compile('[ㄱ-ㅎㅏ-ㅣ가-힣]+')\n","        korean_words = korean_pattern.findall(text)\n","        return ' '.join(korean_words)\n","    else:\n","        return ''\n","\n","gwa_df['clean'] = gwa_df['하는일'].apply(extract_korean_text)\n","\n","models = DistilBertModel.from_pretrained('monologg/distilkobert')\n","tokenizers = tokenization.KoBertTokenizer.from_pretrained('monologg/kobert')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87W5l1oRU4fU","outputId":"c8689b0b-ab13-430c-a5cd-c27ed0002ecc"},"outputs":[{"name":"stdout","output_type":"stream","text":["모델 가중치를 성공적으로 로드했습니다.\n"]}],"source":["# 모델 생성\n","c_model = model.CustomModel(models, 768, 35)\n","\n","# 미리 학습된 가중치 파일 경로\n","model_checkpoint = \"./minone/model.pth\"\n","\n","# 모델 가중치 파일이 존재하는 경우에만 로드\n","if os.path.exists(model_checkpoint):\n","    parameter = torch.load(model_checkpoint, map_location=torch.device('cpu'))\n","    model_keys = set(c_model.state_dict().keys())\n","    pretrained_keys = set(parameter.keys())\n","    unexpected_keys = pretrained_keys - model_keys\n","\n","    trimmed_state_dict = {k: v for k, v in parameter.items() if k not in unexpected_keys}\n","\n","    c_model.load_state_dict(trimmed_state_dict, strict=False)\n","    print(\"모델 가중치를 성공적으로 로드했습니다.\")\n","else:\n","    print(\"미리 학습된 가중치 파일이 없어 기본 모델을 사용합니다.\")"]},{"cell_type":"markdown","metadata":{"id":"_tX0Ee1fU4fU"},"source":["# 임베딩 추출"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MOedjUUyU4fU"},"outputs":[],"source":["def inference(model, dataloader, device):\n","    model.to(device)\n","    model.eval()\n","\n","    embeddings = []\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for input_ids, attention_mask in dataloader:\n","            input_ids = input_ids.to(device)\n","            attention_mask = attention_mask.to(device)\n","\n","            cls_output, pred = model(input_ids, attention_mask)\n","            predictions.extend(pred.argmax(dim=1).cpu().tolist())\n","\n","            embeddings.append(cls_output)\n","\n","    # 모든 임베딩을 하나의 텐서로 연결\n","    embeddings = torch.cat(embeddings, dim=0)\n","\n","    return embeddings, predictions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IHH2xnOnU4fV"},"outputs":[],"source":["# 하는 일 임베딩\n","FeatureEmbedding = CD.FeatureExtractDataset(gwa_df['clean'].values, tokenizers)\n","FeatureEmbedding_dataloader = torch.utils.data.DataLoader(FeatureEmbedding, batch_size = 1, shuffle=False)\n","cls_output, _ = inference(c_model, FeatureEmbedding_dataloader, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ovb8t8OU4fV"},"outputs":[],"source":["# cls_output을 numpy array로 변환\n","embeddings_np = cls_output.cpu().numpy()\n","\n","# numpy array를 list of arrays로 변환\n","embedding_list = [embeddings_np[i] for i in range(embeddings_np.shape[0])]\n","\n","# DataFrame에 새로운 열로 추가\n","gwa_df['embedding'] = embedding_list\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q8XiWY_KU4fV"},"outputs":[],"source":["data = gwa_df.drop(['하는일',\t'ex_token',\t'ex_text',\t'token'\t,'text'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-K6QmitU4fV"},"outputs":[],"source":["# 임베딩이 텍스트 형태로 나타나는 것에 대한 수정 코드\n","data['embedding'] = data['embedding'].apply(lambda x: list(map(float, x)))\n","\n","# 문자열을 리스트로 변환 후, 각 원소를 float로 변환\n","data['embedding'] = data['embedding'].apply(lambda x: list(map(float, literal_eval(x))))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHoNmtKFU4fV"},"outputs":[],"source":["data.to_csv('../data/gwa_embedding.csv', index_col=0)"]}],"metadata":{"kernelspec":{"display_name":"dck2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}