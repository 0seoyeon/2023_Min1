{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Colab에서 Google 드라이브를 마운트하는 코드\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"cA3grlQZyY6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece"],"metadata":{"id":"Vk7SY7XCaLLt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"211r7yGR3AYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from minone import CD, model, trainer, tokenization"],"metadata":{"id":"d-mvXVovWzKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","import random\n","import os\n","import numpy as np\n","import pandas as pd\n","import re\n","\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","from transformers import AutoTokenizer, AutoModel\n","from transformers import DistilBertModel\n","\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.metrics import f1_score, accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt"],"metadata":{"id":"RXRXriu7ho5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CFG = {\n","    'EPOCHS': 10,\n","    'LEARNING_RATE': 1e-4,\n","    'BATCH_SIZE': 64,\n","    'SEED': 4\n","}"],"metadata":{"id":"btwQs8hC5vkz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def seed_everything(seed=CFG['SEED']):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True"],"metadata":{"id":"78a925NWgz_m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"id":"EH7A1SYBd31R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_data = pd.read_csv('../data/train_data.csv')"],"metadata":{"id":"DC6FQKjgkxDT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models = DistilBertModel.from_pretrained('monologg/distilkobert')\n","tokenizers = tokenization.KoBertTokenizer.from_pretrained('monologg/kobert')"],"metadata":{"id":"XxgeRwKtdzcn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 생성\n","c_model = model.CustomModel(models, 768, 35)\n","\n","# 미리 학습된 가중치 파일 경로\n","model_checkpoint = \"./code/minone/model.pth\"\n","\n","# 모델 가중치 파일이 존재하는 경우에만 로드\n","if os.path.exists(model_checkpoint):\n","    parameter = torch.load(model_checkpoint)\n","    model_keys = set(c_model.state_dict().keys())\n","    pretrained_keys = set(parameter.keys())\n","    unexpected_keys = pretrained_keys - model_keys\n","\n","    trimmed_state_dict = {k: v for k, v in parameter.items() if k not in unexpected_keys}\n","\n","    c_model.load_state_dict(trimmed_state_dict, strict=False)\n","    print(\"모델 가중치를 성공적으로 로드했습니다.\")\n","else:\n","    print(\"미리 학습된 가중치 파일이 없어 기본 모델을 사용합니다.\")"],"metadata":{"id":"N8Zwgs4ofgvX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_size: 검증 세트의 비율 (예: 0.2는 80% 훈련, 20% 검증을 의미)\n","# random_state: 랜덤 시드 값 (동일한 결과를 재현하려면 고정된 값 사용)\n","# stratify: 클래스 레이블을 기반으로 계층적 분할을 수행하여 클래스 분포를 유지\n","\n","train_data, val_data = train_test_split(text_data, test_size=0.2, random_state=4, stratify = text_data['topic'])"],"metadata":{"id":"JBB8xVzGR1xh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reset_index 함수를 사용하여 데이터프레임의 인덱스를 재설정\n","\n","train_data = train_data.reset_index(drop = True)\n","val_data = val_data.reset_index(drop = True)"],"metadata":{"id":"CXqOVvv-SSIM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ClassifierDataset 클래스를 사용하여 훈련 및 검증 데이터셋을 생성\n","# DataLoader를 사용하여 배치로 데이터를 로드\n","\n","train_dataset = CD.ClassifierDataset(train_data, tokenizers, mode=\"train\")\n","valid_dataset = CD.ClassifierDataset(val_data, tokenizers, mode=\"train\")\n","\n","# 훈련 데이터로더 생성\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0, pin_memory=True)\n","\n","# 검증 데이터로더 생성\n","val_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0, pin_memory=True)"],"metadata":{"id":"tKB22-VH576m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha  # 파라미터 alpha: 클래스 불균형 보정에 사용되는 가중치\n","        self.gamma = gamma  # 파라미터 gamma: 손실의 강도를 조절하는 하이퍼파라미터\n","\n","    def forward(self, inputs, targets):\n","        # 1. 교차 엔트로피 손실 계산\n","        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n","\n","        # 2. 확률 값을 계산하고 Focal Loss 계산\n","        pt = torch.exp(-ce_loss)  # 확률 값 계산 (pt = e^(-ce_loss))\n","        F_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss  # Focal Loss 계산\n","\n","        # 3. Focal Loss의 평균 반환\n","        return torch.mean(F_loss)\n"],"metadata":{"id":"H1FpxHjMdS1j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CustomModel을 사용하여 모델을 초기화\n","c_model = model.CustomModel(models, 768, 35)\n","\n","# AdamW를 사용하고 모델의 파라미터를 업데이트\n","optimizer = torch.optim.AdamW(params=c_model.parameters(), lr=CFG[\"LEARNING_RATE\"])\n","\n","# 스케줄러를 초기화합니다. 검증 손실이 개선되지 않을 경우 학습률을 조절\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","\n","# Focal Loss를 초기화,  이 손실 함수는 모델의 출력과 실제 레이블 간의 손실을 계산\n","criterion = FocalLoss().to(device)"],"metadata":{"id":"VKC8t_mD-190"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_train = trainer.Trainer(c_model, optimizer, scheduler, criterion, train_dataloader, val_dataloader,\n","                              CFG['EPOCHS'], device)"],"metadata":{"id":"ULJLCtXZ94GU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델을 훈련하고 손실, 정확도 및 F1 점수를 반환합니다.\n","train_l, val_l, accuracy, f1_score = model_train.train()"],"metadata":{"id":"HFD5Jwco_mKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gc\n","\n","# 현재까지 사용된 메모리를 해제합니다.\n","gc.collect()\n","\n","# CUDA 캐시를 비워줍니다. 이것은 GPU 메모리의 일부를 비워서 메모리를 최적화합니다.\n","torch.cuda.empty_cache()"],"metadata":{"id":"1OSOByF7XWZp"},"execution_count":null,"outputs":[]}]}