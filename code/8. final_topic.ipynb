{"cells":[{"cell_type":"markdown","metadata":{"id":"PuKooXQKZMXU"},"source":["# import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZzzUvLUZZMXW"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import re\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from tqdm import tqdm\n","import torch\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from kiwipiepy import Kiwi\n","\n","from sklearn.decomposition import LatentDirichletAllocation\n","import gensim\n","from gensim.models.coherencemodel import CoherenceModel\n","from sklearn.decomposition import LatentDirichletAllocation\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from gensim.corpora.dictionary import Dictionary\n","from gensim.models import LdaModel\n","from gensim.models.coherencemodel import CoherenceModel\n","from bertopic import BERTopic\n","from sklearn.pipeline import make_pipeline\n","\n","import gensim.corpora as corpora\n","from sklearn.decomposition import NMF\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","from gensim.corpora import Dictionary\n","\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn.feature_extraction.text import CountVectorizer\n","from hdbscan import HDBSCAN\n","\n","\n","from sklearn.pipeline import make_pipeline\n","from sklearn.decomposition import TruncatedSVD\n","\n","from bertopic.backend import BaseEmbedder\n","from sklearn.utils.validation import check_is_fitted, NotFittedError\n","from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors\n"]},{"cell_type":"markdown","metadata":{"id":"v4aMDGm9ZMXY"},"source":["- 토픽의 개수는 각 구마다 평균 부서 숫자가 35이기 때문에 35로 설정함\n","- 토픽모델링에서 일반적인 성능지표로 쓰이는 coherence_score 를 사용하여 성능을 비교하였다"]},{"cell_type":"markdown","metadata":{"id":"Vh_iuYJiZMXY"},"source":["# 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"64oJeiVDZMXY"},"outputs":[],"source":["gwa_df = pd.read_csv('../data/0. 구_과_하는일_통합.csv')\n","minwon_df = pd.read_csv('../data/0. 새올_통합.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6UpvvfxZMXZ"},"outputs":[],"source":["kiwi = Kiwi()\n","\n","def extract_text(text, exclude_keywords=None):\n","    result = kiwi.tokenize(text)\n","    excluded_tokens = set(exclude_keywords) if exclude_keywords else set()\n","    tokens = [token.form for token in result if token.tag in ['NNG', 'NNP'] and token.form not in excluded_tokens and len(token.form) > 1]\n","    return ' '.join(tokens)\n","\n","\n","def extract_token(text, exclude_keywords=None):\n","    result = kiwi.tokenize(text)\n","    excluded_tokens = set(exclude_keywords) if exclude_keywords else set()\n","    tokens = [token.form for token in result if token.tag in ['NNG', 'NNP'] and token.form not in excluded_tokens and len(token.form) > 1]\n","    return tokens\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xe5jxDbSZMXZ"},"outputs":[],"source":["# 논의를 통한 불용어 사전 정의\n","li = ['관리','업무','운영','사업','지원','총괄','관련','계획','시설','민원','센터','처리','추진','유지','조사','수립','예산','신고','지역','사항','시스템','정보','위원회','통합','차량','지도','공공','자료','평가','접수','담당','종합','개선','현장','직원','변경','구역','기관','서울','사례','회계','주요','정책','기획','협의','활성']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZVEzvn_JZMXZ"},"outputs":[],"source":["# 불용어 사전을 적용하지 않은 토큰화된 칼럼과 텍스트 칼럼 생성\n","\n","gwa_df['token'] =  gwa_df['하는일'].apply(extract_token)\n","gwa_df['text'] =  gwa_df['하는일'].apply(extract_text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZgnLT47ZMXZ"},"outputs":[],"source":["# 불용어 사전을 적용한 토큰화된 칼럼과 텍스트 칼럼 생성\n","\n","gwa_df['ex_token'] = gwa_df['하는일'].apply(lambda text: extract_token(text, exclude_keywords=li))\n","gwa_df['ex_text'] = gwa_df['하는일'].apply(lambda text: extract_text(text, exclude_keywords=li))\n"]},{"cell_type":"markdown","metadata":{"id":"9sXzxT1mZMXZ"},"source":["# LDA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6soBfB4mZMXZ"},"outputs":[],"source":["\n","\n","def tfvec(texts, num):\n","    # 1. LDA 모델링\n","    dictionary = Dictionary(texts)\n","    corpus = [dictionary.doc2bow(text) for text in texts]\n","    lda_model = LdaModel(corpus, num_topics=num, id2word=dictionary, random_state=4)\n","\n","    # 2. 각 문서에 대해 가장 높은 확률을 가진 토픽 선택\n","    lda_topic = [max(lda_model.get_document_topics(item), key=lambda x: x[1])[0] for item in corpus]\n","\n","    # 3. 선택된 토픽과 그에 해당하는 단어들을 데이터 프레임에 저장\n","    topics_list = []\n","    topics_words_list = [] # CoherenceModel에 사용할 토픽의 단어 리스트\n","    for topic_id, topic in lda_model.show_topics(num_topics=num, num_words=20, formatted=False):\n","        topic_words = [word[0] for word in topic]\n","        topics_list.append({'Topic': topic_id, 'Words': \" \".join(topic_words)})\n","        topics_words_list.append(topic_words) # 각 토픽의 단어들을 리스트에 추가\n","\n","    topics_df = pd.DataFrame(topics_list)\n","\n","    # 4. coherence_score 구하기\n","    coherence_model = CoherenceModel(topics=topics_words_list, texts=texts, dictionary=dictionary, coherence='c_v')\n","    coherence_score = coherence_model.get_coherence()\n","\n","    return lda_topic, topics_df, coherence_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYXw4rDLZMXa"},"outputs":[],"source":["# 함수 호출\n","topics, topics_df, score = tfvec(gwa_df['token'], num=35)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpABHReyZMXa","outputId":"00b10cdf-3172-452e-a302-04a327badd51"},"outputs":[{"data":{"text/plain":["0.30308447864604476"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LenBkfcMZMXb","outputId":"79c9d6cc-65a9-4d4e-cdc5-807206b7d57b"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.3242473293463132\n"]}],"source":["topics, topics_df, score = tfvec(gwa_df['ex_token'], num=35)\n","print(score)"]},{"cell_type":"markdown","metadata":{"id":"QGxXXHlFZMXb"},"source":["# NMF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UqkVzHLIZMXb"},"outputs":[],"source":["\n","\n","def nmf_topic_modeling(texts, num):\n","    # 1. TF-IDF 벡터화\n","    tfidf_vectorizer = TfidfVectorizer(max_df=0.98, min_df=2)\n","    tfidf = tfidf_vectorizer.fit_transform([\" \".join(text) for text in texts])\n","\n","    # 2. NMF 모델링\n","    nmf_model = NMF(n_components=num, random_state=4, l1_ratio=.5, init='nndsvd').fit(tfidf)\n","\n","    # 3. 각 문서에 대해 가장 높은 확률을 가진 토픽 선택\n","    nmf_topics = nmf_model.transform(tfidf)\n","    most_prob_topic = nmf_topics.argmax(axis=1)\n","\n","    # 4. 선택된 토픽과 그에 해당하는 단어들을 데이터 프레임에 저장\n","    topics_list = []\n","    topics_words_list = []  # CoherenceModel에 사용할 토픽의 단어 리스트\n","    feature_names = tfidf_vectorizer.get_feature_names_out()\n","    for topic_idx, topic in enumerate(nmf_model.components_):\n","        topic_words = [feature_names[i] for i in topic.argsort()[:-20-1:-1]]  # 상위 20개 단어\n","        topics_list.append({'Topic': topic_idx, 'Words': \" \".join(topic_words)})\n","        topics_words_list.append(topic_words) # 각 토픽의 단어들을 리스트에 추가\n","\n","    topics_df = pd.DataFrame(topics_list)\n","\n","    # 5. Coherence score 계산\n","    dictionary = Dictionary(texts)\n","    coherence_model = CoherenceModel(topics=topics_words_list, texts=texts, dictionary=dictionary, coherence='c_v')\n","    coherence_score = coherence_model.get_coherence()\n","\n","    return most_prob_topic, topics_df, coherence_score\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pL-4SP-zZMXb"},"outputs":[],"source":["topics, topics_df, coherence = nmf_topic_modeling(gwa_df['token'].tolist(), num=35)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wzQTbRsTZMXb","outputId":"d27d9490-fcff-4f1a-ef94-8a572bf94317"},"outputs":[{"data":{"text/plain":["0.6960640193939929"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["coherence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXBPANN0ZMXb"},"outputs":[],"source":["topics, topics_df, coherence = nmf_topic_modeling(gwa_df['ex_token'].tolist(), num=35)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4sfD3pgZMXb","outputId":"cefc4512-14a7-4050-d088-11bcb55b9103"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8290314129732812\n"]}],"source":["print(coherence)"]},{"cell_type":"markdown","metadata":{"id":"NRQgGwiOZMXb"},"source":["# BERTopic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5s663GBCZMXb"},"outputs":[],"source":["# 점수를 계산하기 위한 함수\n","def score(df, texts):\n","    # Gensim dictionary 및 corpus 생성\n","    dictionary = Dictionary(texts)\n","    corpus = [dictionary.doc2bow(text) for text in texts]\n","    # Representation 컬럼으로부터 토픽 리스트 생성\n","    topic = df['Representation']\n","    # Coherence 계산\n","    coherence_model = CoherenceModel(topics=topic, texts=texts, dictionary=dictionary, coherence='c_v')\n","    coherence_value = coherence_model.get_coherence()\n","\n","    return coherence_value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1c2Q_Ke3ZMXb"},"outputs":[],"source":["from transformers import AutoModel, AutoTokenizer\n","\n","model = AutoModel.from_pretrained(\"klue/bert-base\")\n","tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uruCHFfSZMXc"},"outputs":[],"source":["vectorizer = CountVectorizer(tokenizer=extract_token, min_df=2)\n","hdbscan_model = HDBSCAN(min_cluster_size=20, metric='euclidean', cluster_selection_method='leaf', prediction_data=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_xI9epuZMXc"},"outputs":[],"source":["# bertopic을 하기 위한 데이터프레임\n","def topicmodel(model, vectorizer, nr_topics, top_n_words, texts, embeddings=None):\n","\n","    topic_model = BERTopic(embedding_model=model,\n","                       vectorizer_model=vectorizer,\n","                       nr_topics=nr_topics,\n","                       top_n_words=top_n_words,\n","                       calculate_probabilities=False)\n","\n","    topics, probs = topic_model.fit_transform(texts.tolist(), embeddings=embeddings)\n","    first_result = topic_model.get_topic_info()\n","\n","    return topics, first_result\n"]},{"cell_type":"markdown","metadata":{"id":"7aHMj0lUZMXc"},"source":["## word2vec"]},{"cell_type":"markdown","metadata":{"id":"C5cBgGGLZMXc"},"source":["### 불용어 사전 적용 x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VNDBoDNjZMXc"},"outputs":[],"source":["sentences = gwa_df['text']\n","model_w2v = Word2Vec(sentences, vector_size=200, window=5, min_count=1, workers=4)\n","\n","\n","# Word2VecKeyedVectors 인스턴스\n","word_vectors = model_w2v.wv\n","# 문서 임베딩 계산: 문서 내의 모든 단어의 임베딩을 평균냄\n","def document_vector(doc, model):\n","    # 해당 문서에 있는 단어 중 모델에 학습된 단어에 대한 임베딩만 사용\n","    doc = [word for word in doc if word in model.wv]\n","    if len(doc) == 0:\n","        return np.zeros(model.vector_size)\n","    else:\n","        return np.mean(model.wv[doc], axis=0)\n","\n","doc_embeddings = np.array([document_vector(doc, model_w2v) for doc in sentences])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O08MBSP0ZMXc"},"outputs":[],"source":["topics, first_result = topicmodel(word_vectors, vectorizer, 35, 20, gwa_df['text'], doc_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xxQZ1mBVZMXc","outputId":"52a1b726-e25f-4fc3-ad0e-9906c04cea77"},"outputs":[{"data":{"text/plain":["0.6805869237420512"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["score(first_result, gwa_df['token'])"]},{"cell_type":"markdown","metadata":{"id":"NKUnnVqzZMXc"},"source":["### 불용어 사전 o"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"867kivaJZMXc"},"outputs":[],"source":["sentences = gwa_df['ex_text']\n","model_w2v = Word2Vec(sentences, vector_size=200, window=5, min_count=1, workers=4)\n","\n","\n","# Word2VecKeyedVectors 인스턴스\n","word_vectors = model_w2v.wv\n","# 문서 임베딩 계산: 문서 내의 모든 단어의 임베딩을 평균냄\n","def document_vector(doc, model):\n","    # 해당 문서에 있는 단어 중 모델에 학습된 단어에 대한 임베딩만 사용\n","    doc = [word for word in doc if word in model.wv]\n","    if len(doc) == 0:\n","        return np.zeros(model.vector_size)\n","    else:\n","        return np.mean(model.wv[doc], axis=0)\n","\n","doc_embeddings = np.array([document_vector(doc, model_w2v) for doc in sentences])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"veVcMK3DZMXc"},"outputs":[],"source":["topics, first_result = topicmodel(word_vectors, vectorizer, 35, 20, gwa_df['ex_text'], doc_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6VOcWaiZMXc","outputId":"17229feb-0e4e-4ac3-a18f-05bb309885c2"},"outputs":[{"data":{"text/plain":["0.802636801313551"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["score(first_result, gwa_df['ex_token'])"]},{"cell_type":"markdown","metadata":{"id":"y-PgojbkZMXc"},"source":["## _sklearn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oImg9VjYZMXc"},"outputs":[],"source":["\n","pipe = make_pipeline(\n","    TfidfVectorizer(),\n","    TruncatedSVD(100)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qzu_KHz0ZMXc"},"outputs":[],"source":["class SklearnEmbedder(BaseEmbedder):\n","    def __init__(self, pipe):\n","        super().__init__()\n","        self.pipe = pipe\n","\n","    def embed(self, documents, verbose=False):\n","        try:\n","            check_is_fitted(self.pipe)\n","            embeddings = self.pipe.transform(documents)\n","        except NotFittedError:\n","            embeddings = self.pipe.fit_transform(documents)\n","\n","        return embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_KXxwpFNZMXd"},"outputs":[],"source":["sklearn_embedder = SklearnEmbedder(pipe)\n"]},{"cell_type":"markdown","metadata":{"id":"B-xl0BPzZMXd"},"source":["### 불용어 사전 x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8KOJllzPZMXd"},"outputs":[],"source":["topics, first_result = topicmodel(sklearn_embedder, vectorizer, 35, 20, gwa_df['text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ckhM4FY4ZMXd","outputId":"a4d09c71-cbea-49ee-fca2-8874c414aca1"},"outputs":[{"data":{"text/plain":["0.7073256465440682"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["score(first_result, gwa_df['token'])"]},{"cell_type":"markdown","metadata":{"id":"QVxUb0YbZMXe"},"source":["### 불용어 사전 o"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"us-sRGzpZMXe","outputId":"9b651959-7a46-4690-bc67-f05015537aea"},"outputs":[{"data":{"text/plain":["0.8048639798954497"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["topics, first_result = topicmodel(sklearn_embedder, vectorizer, 35, 20, gwa_df['ex_text'])\n","score(first_result, gwa_df['ex_token'])"]},{"cell_type":"markdown","metadata":{"id":"3QfMdjWlZMXe"},"source":["## SEBRT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7JwlmwlZMXe"},"outputs":[],"source":["topics, first_result = topicmodel(model, vectorizer, 35, 20, gwa_df['text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yU74AtxnZMXe","outputId":"61eee9ce-0de4-4655-f6d5-124e55474850"},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","0.3360386520492728\n"]}],"source":["print(score(first_result, gwa_df['token']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CcF2AvlZMXe"},"outputs":[],"source":["topics, first_result = topicmodel(model, vectorizer, 35, 20, gwa_df['ex_text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VWxqO2zWZMXe","outputId":"7d09f197-39ca-400f-f5cf-085102264ea6"},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","0.525536396733981\n"]}],"source":["print(score(first_result, gwa_df['ex_token']))"]},{"cell_type":"markdown","metadata":{"id":"AcJryRr-ZMXe"},"source":["# 최종 최적화"]},{"cell_type":"markdown","metadata":{"id":"kNocxm19ZMXe"},"source":["가장 스코어가 높았던 NMF 방법과 불용어 사전을 이용해 토픽모델링을 수행한다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBkzzK67ZMXe"},"outputs":[],"source":["from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n","from sklearn.decomposition import NMF\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from gensim.corpora import Dictionary\n","from gensim.models.coherencemodel import CoherenceModel\n","\n","# 최적화할 함수 정의\n","def objective(params):\n","    # 1. TF-IDF 벡터화\n","    tfidf_vectorizer = TfidfVectorizer(max_df=params['max_df'], min_df=int(params['min_df']))\n","    tfidf = tfidf_vectorizer.fit_transform([\" \".join(text) for text in texts])\n","\n","    # 2. NMF 모델링\n","    nmf_model = NMF(n_components=35, init=params['init'], solver=params['solver'],l1_ratio=params['l1_ratio'], random_state=4).fit(tfidf)\n","\n","    nmf_topics = nmf_model.transform(tfidf)\n","\n","    topics_words_list = []\n","    feature_names = tfidf_vectorizer.get_feature_names_out()\n","    for topic in nmf_model.components_:\n","        topic_words = [feature_names[i] for i in topic.argsort()[:-20-1:-1]]\n","        topics_words_list.append(topic_words)\n","\n","    dictionary = Dictionary(texts)\n","    coherence_model = CoherenceModel(topics=topics_words_list, texts=texts, dictionary=dictionary, coherence='c_v')\n","    coherence_score = coherence_model.get_coherence()\n","\n","    # 최대화 하려는 경우, score를 음수로 반환\n","    return {'loss': -coherence_score, 'status': STATUS_OK}\n","\n","# 파라미터 공간 정의 (n_components 추가)\n","space = {\n","    'max_df': hp.uniform('max_df', 0.7, 1.0),\n","    'min_df': hp.quniform('min_df', 2, 5, 1),\n","    'l1_ratio': hp.uniform('l1_ratio', 0, 1),\n","    'init': hp.choice('init', ['random', 'nndsvd', 'nndsvda', 'nndsvdar']),\n","    'solver': hp.choice('solver', ['cd', 'mu'])\n","}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q6lH8TL9ZMXf","outputId":"c0711118-1a81-4836-aa22-7ac3fdc32f56"},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|██████████| 100/100 [15:10<00:00,  9.11s/trial, best loss: -0.8368117229971074]\n","Best hyperparameters: {'init': 2, 'l1_ratio': 0.9675387548037933, 'max_df': 0.7322978491623063, 'min_df': 3.0, 'solver': 0}\n"]}],"source":["# 최적화 실행\n","texts = gwa_df['ex_token'].tolist()\n","trials = Trials()\n","best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)\n","\n","print(\"Best hyperparameters:\", best)"]},{"cell_type":"markdown","metadata":{"id":"w8zOBgb8ZMXf"},"source":["최종 스코어는 0.8368117229971074 이다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRoQfVq1ZMXf"},"outputs":[],"source":["# 최적의 파라미터를 사용하여 nmf_topic_modeling 호출\n","def nmf_topic_modeling(texts, best_params):\n","    # 1. TF-IDF 벡터화\n","    tfidf_vectorizer = TfidfVectorizer(max_df=best_params['max_df'], min_df=int(best_params['min_df']))\n","    tfidf = tfidf_vectorizer.fit_transform([\" \".join(text) for text in texts])\n","\n","    # 2. NMF 모델링\n","    nmf_model = NMF(\n","        n_components=35,\n","        init='nndsvdar',\n","        solver='cd',\n","        l1_ratio=best_params['l1_ratio'],\n","        random_state=4\n","    ).fit(tfidf)\n","\n","    # 3. 각 문서에 대해 가장 높은 확률을 가진 토픽 선택\n","    nmf_topics = nmf_model.transform(tfidf)\n","    most_prob_topic = nmf_topics.argmax(axis=1)\n","\n","    # 4. 선택된 토픽과 그에 해당하는 단어들을 데이터 프레임에 저장\n","    topics_list = []\n","    topics_words_list = []  # CoherenceModel에 사용할 토픽의 단어 리스트\n","    feature_names = tfidf_vectorizer.get_feature_names_out()\n","    for topic_idx, topic in enumerate(nmf_model.components_):\n","        topic_words = [feature_names[i] for i in topic.argsort()[:-20-1:-1]]  # 상위 20개 단어\n","        topics_list.append({'Topic': topic_idx, 'Words': \" \".join(topic_words)})\n","        topics_words_list.append(topic_words) # 각 토픽의 단어들을 리스트에 추가\n","\n","    topics_df = pd.DataFrame(topics_list)\n","\n","    # 5. Coherence score 계산\n","    dictionary = Dictionary(texts)\n","    coherence_model = CoherenceModel(topics=topics_words_list, texts=texts, dictionary=dictionary, coherence='c_v')\n","    coherence_score = coherence_model.get_coherence()\n","\n","    return most_prob_topic, topics_df, coherence_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BPmXeqAAZMXf"},"outputs":[],"source":["# 최적의 파라미터로 함수 호출\n","topics, topics_df, coherence = nmf_topic_modeling(texts, best)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"joRUzSm1ZMXf","outputId":"0c6a4c42-1c8e-48ba-ac9e-6b7df2ddd88b"},"outputs":[{"data":{"text/plain":["0.8368117229971074"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["coherence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fpw71QgUZMXg","outputId":"d5869353-5dc2-443d-9d7d-6de37be8e7cb"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Topic</th>\n","      <th>Words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>건축 건축물 인허가 안전 공사 공사장 점검 기계 감독 설계 분야 기술 해체 시설물 ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>급여 의료 자활 보장 기초 수급자 차상위 대상자 결정 연금 주거 생계 생활 복지 변...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>소득세 지방 면허 주민세 징수 부과 자동차세 취득세 사업소 등록 수시 개인 종업원 ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>건강 금연 방문 예방 보건 접종 의료 정신 진료 코로나 검진 증진 영양 감염병 간호...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>아동 청소년 학대 보호 드림 스타트 친화 권리 복지 여성 돌봄 연계 피해 서비스 양...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>자동차 교통 자전거 등록 화물 이전 방치 유발 운송 교통안전 버스 보험 운행 과태료...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>재정 구정 구청장 편성 지방 심사 자치 성과 규제 혁신 회의 법규 간주 지속 교부금...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>도로 굴착 가로등 제설 공사 복구 보도 조명 시설물 보안등 보수 순찰 감독 포장 설...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>지구 도시 단위 개발 정비 촉진 역세권 디자인 재생 일대 건축 복합 행위 중심 타운...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>어린이집 보육 국공립 여성 가정 육아 부모 가족 교직원 교사 민간 보육료 안심 양성...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>식품 업소 위생 접객 공중위생 음식점 제조 영업 원산지 처분 판매업 점검 판매 행정...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>폐기물 청소 투기 무단 활용 음식물 배출 자원 종량제 순환 무관 운행 봉투 분리 활...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>체육 체육회 대회 스포츠 교실 생활 구민 종목 수영장 축구 풋살 관광 강좌 건립 체...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>부동산 주소 거래 토지 지가 지적 중개업 도로명 공시 개별 부여 측량 중개 이동 정...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>여권 관계 가족 기록 발급 등록 교부 정정 등록부 심사 증명 발급기 유기 기록물 문...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>청년 일자리 경제 취업 사회 기업 창업 창출 구인 구직 직업소개소 뉴딜 캠퍼스 노동...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>공원 조성 녹지 근린공원 산림 가로수 생태 조경 어린이 도시 농업 수목 녹지대 개발...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>주차장 주정차 단속 주차 불법 공영 위반 과태료 부설 의견 진술 거주자 압류 우선 ...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>펌프장 빗물 하수 하천 하수도 수방 지하수 시설물 풍수 설비 공사 수문 설계 전기 ...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>광고물 옥외 불법 정비 유동 점용 허가 간판 가게 디자인 거리 보상 광고 노점 가로...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>20</td>\n","      <td>노인 경로당 어르신 요양 복지 재가 장기 복지관 연금 일자리 경로 기초 돌봄 지회 ...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21</td>\n","      <td>장애인 장애 발달 복지 편의 재활 중증 거주 주차 서비스 활동 자립생활 자립 전용 ...</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>22</td>\n","      <td>주택 공동 임대 사업자 정비 건축물 허가 조합 위반 아파트 임대차 규모 재생 건축 ...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23</td>\n","      <td>환경 배출 먼지 소음 에너지 가스 탄소 오염 전기 충전 중립 대기 기후 사업장 자동...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>24</td>\n","      <td>안전 재난 민방위 재해 중대 훈련 보건 산업 점검 교육 대응 매뉴얼 대책 관리자 본...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>25</td>\n","      <td>평생 교육 학습 학교 진로 프로그램 미래 학습관 체험 도서관 경비 청소년 배움터 진...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>26</td>\n","      <td>재산세 취득세 법인 부동산 부과 가격 징수 개인 면허 등록 과세 주택 지방세 개별 ...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>27</td>\n","      <td>스마트 통신 영상 관제 구축 행정 빅데이터 홈페이지 데이터 통신망 보안 도시 개인 ...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>28</td>\n","      <td>복지 사회 돌봄 긴급 보훈 보장 서비스 희망 위기 협의체 가구 대상자 복지관 사각지...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>29</td>\n","      <td>체납 압류 지방세 영치 징수 세외 수입 공매 해제 체납자 채권 부동산 번호판 고액 ...</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>30</td>\n","      <td>시장 전통 동물 상점가 상공인 상권 기업 판매업 골목 현대 육성 등록 중소 중소기업...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>31</td>\n","      <td>계약 재산 지출 공유 물품 담당관 세출 용역 재정 공유재산 공사 결산 구비 조달 구...</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>32</td>\n","      <td>청사 인사 공무원 교류 친절 구청장 휴양소 행사 방호 평정 연수 행정 후생 구내식당...</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>33</td>\n","      <td>문화 도서관 관광 예술 문화재 축제 게임 구립 문화원 음악 종교 재단 산업 진흥 공...</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>34</td>\n","      <td>주민 자치 자원봉사 마을 자치회 회관 봉사 협치 청사 공동체 자원 기부 선거 구민 ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Topic                                              Words\n","0       0  건축 건축물 인허가 안전 공사 공사장 점검 기계 감독 설계 분야 기술 해체 시설물 ...\n","1       1  급여 의료 자활 보장 기초 수급자 차상위 대상자 결정 연금 주거 생계 생활 복지 변...\n","2       2  소득세 지방 면허 주민세 징수 부과 자동차세 취득세 사업소 등록 수시 개인 종업원 ...\n","3       3  건강 금연 방문 예방 보건 접종 의료 정신 진료 코로나 검진 증진 영양 감염병 간호...\n","4       4  아동 청소년 학대 보호 드림 스타트 친화 권리 복지 여성 돌봄 연계 피해 서비스 양...\n","5       5  자동차 교통 자전거 등록 화물 이전 방치 유발 운송 교통안전 버스 보험 운행 과태료...\n","6       6  재정 구정 구청장 편성 지방 심사 자치 성과 규제 혁신 회의 법규 간주 지속 교부금...\n","7       7  도로 굴착 가로등 제설 공사 복구 보도 조명 시설물 보안등 보수 순찰 감독 포장 설...\n","8       8  지구 도시 단위 개발 정비 촉진 역세권 디자인 재생 일대 건축 복합 행위 중심 타운...\n","9       9  어린이집 보육 국공립 여성 가정 육아 부모 가족 교직원 교사 민간 보육료 안심 양성...\n","10     10  식품 업소 위생 접객 공중위생 음식점 제조 영업 원산지 처분 판매업 점검 판매 행정...\n","11     11  폐기물 청소 투기 무단 활용 음식물 배출 자원 종량제 순환 무관 운행 봉투 분리 활...\n","12     12  체육 체육회 대회 스포츠 교실 생활 구민 종목 수영장 축구 풋살 관광 강좌 건립 체...\n","13     13  부동산 주소 거래 토지 지가 지적 중개업 도로명 공시 개별 부여 측량 중개 이동 정...\n","14     14  여권 관계 가족 기록 발급 등록 교부 정정 등록부 심사 증명 발급기 유기 기록물 문...\n","15     15  청년 일자리 경제 취업 사회 기업 창업 창출 구인 구직 직업소개소 뉴딜 캠퍼스 노동...\n","16     16  공원 조성 녹지 근린공원 산림 가로수 생태 조경 어린이 도시 농업 수목 녹지대 개발...\n","17     17  주차장 주정차 단속 주차 불법 공영 위반 과태료 부설 의견 진술 거주자 압류 우선 ...\n","18     18  펌프장 빗물 하수 하천 하수도 수방 지하수 시설물 풍수 설비 공사 수문 설계 전기 ...\n","19     19  광고물 옥외 불법 정비 유동 점용 허가 간판 가게 디자인 거리 보상 광고 노점 가로...\n","20     20  노인 경로당 어르신 요양 복지 재가 장기 복지관 연금 일자리 경로 기초 돌봄 지회 ...\n","21     21  장애인 장애 발달 복지 편의 재활 중증 거주 주차 서비스 활동 자립생활 자립 전용 ...\n","22     22  주택 공동 임대 사업자 정비 건축물 허가 조합 위반 아파트 임대차 규모 재생 건축 ...\n","23     23  환경 배출 먼지 소음 에너지 가스 탄소 오염 전기 충전 중립 대기 기후 사업장 자동...\n","24     24  안전 재난 민방위 재해 중대 훈련 보건 산업 점검 교육 대응 매뉴얼 대책 관리자 본...\n","25     25  평생 교육 학습 학교 진로 프로그램 미래 학습관 체험 도서관 경비 청소년 배움터 진...\n","26     26  재산세 취득세 법인 부동산 부과 가격 징수 개인 면허 등록 과세 주택 지방세 개별 ...\n","27     27  스마트 통신 영상 관제 구축 행정 빅데이터 홈페이지 데이터 통신망 보안 도시 개인 ...\n","28     28  복지 사회 돌봄 긴급 보훈 보장 서비스 희망 위기 협의체 가구 대상자 복지관 사각지...\n","29     29  체납 압류 지방세 영치 징수 세외 수입 공매 해제 체납자 채권 부동산 번호판 고액 ...\n","30     30  시장 전통 동물 상점가 상공인 상권 기업 판매업 골목 현대 육성 등록 중소 중소기업...\n","31     31  계약 재산 지출 공유 물품 담당관 세출 용역 재정 공유재산 공사 결산 구비 조달 구...\n","32     32  청사 인사 공무원 교류 친절 구청장 휴양소 행사 방호 평정 연수 행정 후생 구내식당...\n","33     33  문화 도서관 관광 예술 문화재 축제 게임 구립 문화원 음악 종교 재단 산업 진흥 공...\n","34     34  주민 자치 자원봉사 마을 자치회 회관 봉사 협치 청사 공동체 자원 기부 선거 구민 ..."]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["topics_df\n","# 확인 결과 잘 나눠진 모습을 확인할 수 있다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yVK3LfeXZMXg"},"outputs":[],"source":["# 토픽값에 따른 부서가 묶인 것을 확인\n","gwa_df['topic'] = topics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dAF-RueaZMXg"},"outputs":[],"source":["grouped_values = gwa_df.groupby('topic')['과'].apply(list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5IVd07cZMXg","outputId":"b7f318b0-d8c8-40cb-fa94-61088ae7881a"},"outputs":[{"data":{"text/plain":["topic\n","0     [건축과, 건축과, 건축과, 건축과, 건축과, 건축과, 건축과, 건축지원과, 건축과...\n","1     [사회복지장애인과, 사회보장과, 생활보장과, 생활보장과, 생활보장과, 생활복지과, ...\n","2     [세무2과, 지방소득세과, 지방소득세과, 세무2과, 세무2과, 지방소득세과, 세무과...\n","3     [보건정책과, 보건의료과, 건강관리과, 보건지소, 보건행정과, 질병관리과, 건강관리...\n","4     [아동청소년과, 가족정책과, 아동청소년과, 청소년과, 아동청소년과, 아동청소년과, ...\n","5     [교통행정과, 교통행정과, 자동차민원과, 교통행정과, 교통행정과, 교통행정과, 교통...\n","6     [기획예산과, 기획예산과, 기획예산과, 홍보과, 기획예산과, 기획예산과, 기획예산과...\n","7     [도로과, 도로관리과, 도로과, 도로관리과, 도로과, 도로관리과, 도로과, 도로관리...\n","8     [도시계획과, 도시계획과, 도시계획과, 주거정비과, 도시계획과, 도시계획과, 주거정...\n","9     [가정복지과, 보육지원과, 보육지원과, 가족정책과, 여성가족과, 가족정책과, 여성가...\n","10    [보건위생과, 위생과, 보건위생과, 보건위생과, 위생관리과, 위생과, 보건위생과, ...\n","11    [청소과, 자원순환과, 청소행정과, 청소행정과, 자원순환과, 청소행정과, 청소행정과...\n","12    [체육진흥과, 생활체육과, 생활체육과, 체육진흥과, 체육정책과, 체육진흥과, 생활체...\n","13    [부동산정보과, 부동산정보과, 부동산정보과, 부동산정보과, 부동산정보과, 부동산정보...\n","14    [민원여권과, 민원여권과, 민원여권과, 민원여권과, 민원여권과, 민원여권과, 민원여...\n","15    [일자리청년과, 일자리정책과, 일자리정책과, 일자리지원과, 일자리정책과, 청년정책과...\n","16    [공원녹지과, 공원녹지과, 푸른도시과, 공원녹지과, 공원녹지과, 공원녹지과, 공원녹...\n","17    [교통지도과, 주차관리과, 주차행정과, 주차관리과, 주차관리과, 교통지도과, 주차행...\n","18    [치수과, 치수과, 치수과, 물관리과, 치수과, 치수과, 치수과 , 물관리과, 치수...\n","19    [가로경관과, 도시계획과, 건설관리과, 도시경관과, 건설관리과, 도시디자인과, 건설...\n","20    [어르신복지과, 어르신복지과, 어르신복지과, 어르신,장애인과, 어르신복지과, 어르신...\n","21    [장애인복지과, 장애인복지과, 장애인복지과, 장애인복지과, 장애인사회보장과, 장애인...\n","22    [주택관리과, 주거사업과, 주택과, 재건축사업과, 공동주택과, 재건축재개발과, 주택...\n","23    [환경과, 환경과, 기후환경과, 환경과, 녹색환경과, 녹색환경과, 기후환경과, 환경...\n","24    [도시안전과, 재난안전과, 건축안전센터, 재난안전과, 안전치수과, 안전관리과, 안전...\n","25    [교육지원과, 교육지원과, 교육지원과, 교육지원과, 교육지원과, 교육지원과, 교육지...\n","26    [세무1과, 재산세과, 재산세과, 세무1과, 세무1과, 재산취득세과, 세정과, 재산...\n","27    [디지털도시과, 스마트정보과, 스마트도시과, 디지털정보과, 홍보정책과, 스마트도시과...\n","28    [복지정책과, 복지정책과, 복지정책과, 복지정책과, 복지정책과, 복지정책과, 복지정...\n","29    [세무관리과, 세무관리과, 세무관리과, 38세금징수과, 징수과, 징수과, 세무2과,...\n","30    [지역경제과, 지역경제과, 지역경제과, 지역경제과, 지역경제과, 일자리벤처과, 지역...\n","31    [재무과, 재무과, 재무과, 재무과, 재무과, 재무과, 재무과, 재무과, 재무과, ...\n","32    [총무과, 총무과, 행정지원과, 행정지원과, 행정지원과, 행정지원과, 행정지원과, ...\n","33    [문화예술과, 문화도시과, 관광진흥과, 문화예술과, 문화관광체육과, 문화체육과, 문...\n","34    [자치행정과, 주민자치과, 자치행정과, 자치행정과, 자치행정과, 협치분권과, 자치행...\n","Name: 과, dtype: object"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# 토픽별로 비슷한 과들이 매핑되어 있는 것을 확인할 수 있다.\n","grouped_values"]}],"metadata":{"kernelspec":{"display_name":"dck2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}